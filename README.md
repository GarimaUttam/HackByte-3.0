# ğŸ­ FaceGuard â€“ Deepfake Image & Video Detector Extension

## ğŸ” About the Project

**FaceGuard** is a powerful browser extension backed by a deep learning model that detects whether an image or video contains a real human face or one generated using AI (deepfakes). It allows users to:

- ğŸ–¼ï¸ Right-click on any image/video and instantly get authenticity results.
- ğŸ“ Manually drop/upload files via the popup interface.
- ğŸ“Š Receive confidence scores along with predictions.

This solution combines cutting-edge AI with user-friendly UX to fight against misinformation, fake news, and manipulated content.

---

## ğŸ’¡ Why We Built This

With the rise of generative AI tools, it's becoming increasingly difficult to distinguish between real and AI-generated media. Deepfakes pose serious threats to:

- ğŸ” Personal identity
- ğŸ“° Media authenticity
- ğŸ—³ï¸ Election misinformation
- ğŸ§  Public perception

FaceGuard helps users identify such content instantly and stay informed. We envision it as a **personal media watchdog** in your browser.

---

## ğŸ§  The AI Model

Our backend uses a **MobileNetV2**-based convolutional neural network, fine-tuned on a curated deepfake detection dataset.

### âš™ï¸ Key Features:

- âœ… Lightweight & fast inference
- âœ… Trained for binary classification: `real` vs `fake`
- âœ… Used both image-based and frame-based analysis for videos

The model returns:

- **Prediction**: `real` or `fake`
- **Confidence score**: Probability of authenticity

---

## ğŸ§© Extension Features

| Feature                 | Description                                       |
| ----------------------- | ------------------------------------------------- |
| ğŸ–±ï¸ Right-click Check    | Check any image/video on the web via context menu |
| ğŸ“ File Upload          | Drop/upload your own files in popup               |
| ğŸ”¥ Real-time Result     | Get prediction and confidence instantly           |
| ğŸ” Secure Communication | API requests made to a backend deepfake model     |

---

## ğŸš€ How It Works

1. **Frontend**: Chrome Extension (Popup UI + Context Menu)
2. **Backend**: FastAPI + MobileNetV2 deepfake detection model
3. **Communication**: REST API with endpoints for:
   - `/predict-image/`
   - `/predict-video/`

When a user uploads or right-clicks on media:

- The media is sent to the API
- It returns prediction + confidence
- Results are shown in the extension (with emoji cues!)

### ğŸŒ Detailed Project Flow Diagram

```markdown
flowchart TD
A[User Interaction] -->|Right-click on media or upload file| B[Chrome Extension]
B -->|Send media to backend| C[FastAPI Backend]
C -->|Determine media type| D{Media Type?}
D -->|Image| E[Image Prediction Endpoint (/predict-image/)]
D -->|Video| F[Video Prediction Endpoint (/predict-video/)]
E -->|Process image| G[MobileNetV2 Model]
F -->|Extract frame and process| G[MobileNetV2 Model]
G -->|Generate prediction + confidence| H[FastAPI Backend]
H -->|Return results| B
B -->|Display results| I[User Interface]
```

ğŸ› ï¸ Explanation of the Flow
User Interaction:

# Users can interact with the extension in two ways:
1. Right-click on media (image or video) on a webpage.
2. Upload media (image or video) via the popup interface.

# Frontend (Chrome Extension):
1. The extension captures the media URL or file and sends it to the backend API.
2. For videos, a frame is extracted using the <canvas> element before sending it to the backend.

# Backend (FastAPI):
The backend determines the media type (image or video) and routes the request to the appropriate endpoint:
1. /predict-image/ for images.
2. /predict-video/ for videos.
The backend processes the media using the MobileNetV2 deepfake detection model.

# Deepfake Detection Model (MobileNetV2):
The model analyzes the media and generates:
1. A prediction: real or fake.
2. A confidence score: Probability of authenticity.

# Results Handling:
1. The backend returns the prediction and confidence score to the frontend.
2. The extension displays the results in the popup or as a notification, with visual cues (e.g., emojis, colors).

---

1. Frontend Workflow
flowchart TD
    A[User Action] -->|Right-click or Upload| B[Chrome Extension]
    B -->|Send media| C[Handle File]
    C -->|Determine type| D{Media Type?}
    D -->|Image| E[Send to /predict-image/]
    D -->|Video| F[Extract Frame]
    F -->|Send frame| G[Send to /predict-video/]
    E & G -->|Receive results| H[Display Results]

---

2. Backend Workflow
flowchart TD
    A[Receive Media] -->|Route to endpoint| B{Endpoint?}
    B -->|/predict-image/| C[Process Image]
    B -->|/predict-video/| D[Process Video]
    C & D -->|Analyze with MobileNetV2| E[Generate Prediction + Confidence]
    E -->|Return results| F[Frontend]

---

## ğŸ› ï¸ Tech Stack

- ğŸ§  **Model**: MobileNetV2 (TensorFlow / Keras)
- âš™ï¸ **Backend**: FastAPI
- ğŸ§© **Frontend**: Chrome Extension (HTML, CSS, JS)
- â˜ï¸ **Deployment**: Render for backend APIs

---

## ğŸ¤ Future Scope

- ğŸ§¬ Fine-tune model on more complex datasets (DFDC, CelebDF)
- ğŸ§  Integrate multi-frame analysis for video detection
- ğŸŒ Support Firefox & Edge extensions
- ğŸ“¦ Chrome Web Store publishing

---

## ğŸ“„ License

MIT License. Feel free to fork and enhance this tool! ğŸ™Œ
